# 大语言模型中文提问数学能力评估

这个项目提供了一个自动化工具，用于评估大语言模型（如 GPT-3.5、GPT-4）解决基础数学问题的能力。

## 评估结果

以下表格展示了各个模型在不同类型数学问题上的正确率（%）：

| 问题类型 | GPT-3.5-turbo | GPT-4 | GPT-4 (older) | Claude-3-sonnet | DeepSeek Chat |
|----------|---------------|-------|---------------|-----------------|----------------|
| 2D+ | 100.0 | 100.0 | 100.0 | 100.0 | 100.0 |
| 2D- | 100.0 | 100.0 | 100.0 | 100.0 | 100.0 |
| 3D+ | 100.0 | 100.0 | 100.0 | 100.0 | 99.0 |
| 3D- | 100.0 | 100.0 | 100.0 | 100.0 | 100.0 |
| 4D+ | 100.0 | 100.0 | 100.0 | 100.0 | 100.0 |
| 4D- | 100.0 | 100.0 | 99.0 | 100.0 | 99.0 |
| 5D+ | 99.0 | 99.0 | 100.0 | 98.0 | 98.0 |
| 5D- | 100.0 | 98.0 | 98.0 | 99.0 | 97.0 |
| 2Dx | 100.0 | 100.0 | 100.0 | 100.0 | 100.0 |
| 1DC | 100.0 | 100.0 | 100.0 | 100.0 | 100.0 |
| CCC | 21.0 | 14.0 | 21.0 | 25.0 | 13.0 |

注：
- 2D+/- 表示两位数加/减法
- 3D+/- 表示三位数加/减法
- 4D+/- 表示四位数加/减法
- 5D+/- 表示五位数加/减法
- 2Dx 表示两位数乘法
- 1DC 表示一位数综合运算
- CCC 表示中文字符计数

### 主要观察

1. 除了中文字符计数（CCC）任务外，所有模型在基础数学运算上表现出色，正确率普遍在 97% 以上。

2. 在中文字符计数任务上，所有模型表现较差：
   - Claude-3-sonnet 表现最好，但正确率仅为 25%
   - GPT-3.5-turbo 和 GPT-4 (older version) 次之，正确率为 21%
   - GPT-4 和 DeepSeek Chat 表现最差，正确率分别为 14% 和 13%

3. 在高位数运算（如五位数加减法）上，模型表现略有下降，但仍保持在 97% 以上的高正确率。

4. 所有模型在两位数乘法和一位数综合运算上都达到了 100% 的正确率。

这些结果表明，当前的大语言模型在处理基础数学运算时表现出色，但在特定任务（如中文字符计数）上仍有显著的改进空间。

## 项目结构

```
.
├── src/
│   ├── generate_data.py    # 数据集生成脚本
│   └── evaluate.py         # 模型评估脚本
├── scripts/
│   ├── generate_all.sh     # 生成数据集的执行脚本
│   └── evaluate.sh         # 运行评估的执行脚本
├── dataset/                # 存放生成的数据集
├── results/                # 存放评估结果
├── .env                    # 环境变量配置文件
└── README.md              
```

## 功能特性

### 支持的数学问题类型

1. **两位数加法 (2D+)** - 从 [0,100) 范围内随机选择两个整数相加
2. **两位数减法 (2D-)** - 从 [0,100) 范围内随机选择两个整数相减
3. **三位数加法 (3D+)** - 从 [0,1000) 范围内随机选择两个整数相加
4. **三位数减法 (3D-)** - 从 [0,1000) 范围内随机选择两个整数相减
5. **四位数加法 (4D+)** - 从 [0,10000) 范围内随机选择两个整数相加
6. **四位数减法 (4D-)** - 从 [0,10000) 范围内随机选择两个整数相减
7. **五位数加法 (5D+)** - 从 [0,100000) 范围内随机选择两个整数相加
8. **五位数减法 (5D-)** - 从 [0,100000) 范围内随机选择两个整数相减
9. **两位数乘法 (2Dx)** - 从 [0,100) 范围内随机选择两个整数相乘
10. **一位数综合运算 (1DC)** - 三个一位数的综合运算，包括加减乘

## 安装和配置

### 环境要求

- Python 3.8+
- OpenAI API 密钥

### 安装依赖

```bash
# 创建虚拟环境
python -m venv .venv

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# 安装依赖包
pip install -r requirements.txt
```

### 配置环境变量

创建 `.env` 文件并配置以下变量：

```env
OPENAI_API_KEY=your_api_key_here
OPENAI_API_BASE=https://openai.note-card.com/v1
```

可以使用api镜像站，方便的切换200多种模型：https://openai.note-card.com

## 使用说明

### 生成数据集

```bash
# 运行数据生成脚本
./scripts/生成数据集.sh
```

这将在 `dataset` 目录下生成包含所有类型数学问题的数据集。

### 运行评估

```bash
# 运行评估脚本
./scripts/评估openai模型.sh
```

评估结果将保存在 `results` 目录下，包括：
- 每个问题的具体评估结果
- 按问题类型统计的正确率
- 详细的错误分析（如果有）

## 评估结果示例

```json
{
  "statistics": {
    "2D+": {
      "correct": 95,
      "total": 100,
      "accuracy": "95.00%"
    },
    // ... 其他类型的统计信息
  },
  "results": [
    {
      "problem": "48 加 76 是多少？",
      "correct_answer": "124",
      "model_answer": "124",
      "is_correct": true,
      "problem_type": "2D+"
    },
    // ... 更多详细结果
  ]
}
```

## 自定义和扩展

### 添加新的问题类型

1. 在 `generate_data.py` 中添加新的问题生成函数
2. 更新 `ProblemType` 枚举类
3. 在生成脚本中添加新类型的处理逻辑

### 修改评估参数

可以通过命令行参数调整评估行为：
- `--model`: 选择使用的模型（默认：gpt-3.5-turbo）
- `--input_path`: 指定输入数据集路径
- `--output_path`: 指定结果保存路径

## 注意事项

1. 请确保 `.env` 文件中的 API 密钥安全性
2. 评估过程可能需要较长时间，取决于数据集大小和 API 响应速度
3. 建议定期备份评估结果
4. API 调用可能产生费用，请注意控制数据集大小


## 结语

本次评测展示了当前主流大语言模型在中文数学问答方面的能力全貌。结果表明，这些模型在基础数学运算方面已经达到了很高的水平，但在特定任务上仍有明显短板。这既肯定了大语言模型的进步，也指出了未来改进的方向。

## 参考文献
Brown, Tom, et al. "Language models are few-shot learners." Advances in neural information processing systems 33 (2020): 1877-1901.

